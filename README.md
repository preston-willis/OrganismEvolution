# Organism Evolution Simulation

A GPU-accelerated evolutionary simulation where organisms learn to distribute energy using neural networks. The project uses Convolutional Neural Networks (CNNs) generated by Compositional Pattern-Producing Networks (CPPNs) to control energy distribution and reproduction in a cellular automata environment.

## Quick Start

**Before you begin, please run:**

```bash
python3 main.py --help
```

This will display comprehensive documentation including:
- All command-line arguments
- Keyboard controls for interactive simulation
- Configuration parameters and their defaults
- Training options

## Project Overview

### Core Concept

This simulation models organisms as collections of cells that must:
- Harvest energy from their environment
- Distribute energy efficiently among neighboring cells
- Reproduce by creating new cells when energy thresholds are met
- Survive in dynamic environments with varying energy distributions

### Key Technologies

- **CNN-based Energy Distribution**: Each organism uses a Convolutional Neural Network to decide how to distribute energy to its 3x3 neighborhood
- **CPPN Weight Generation**: CNN weights are generated by Compositional Pattern-Producing Networks, creating structured, evolvable neural architectures
- **Genetic Algorithm**: Populations of CNNs evolve over generations, with fitness based on sustained cell count
- **GPU Acceleration**: Full simulation runs on GPU (MPS/CUDA) for high-performance computation
- **OpenGL Rendering**: Real-time visualization of organism behavior and energy dynamics

### Architecture

The simulation consists of several key components:

1. **Environment**: Generates terrain with energy sources using various algorithms (sine waves, perlin noise, energy masks)
2. **Organism Manager**: Manages cell topology, energy matrices, and reproduction logic
3. **CNN Controller**: Uses neural networks to determine energy distribution patterns
4. **Evolution Driver**: Runs genetic algorithm to evolve better CNNs over generations
5. **Renderer**: OpenGL-based visualization with multiple view modes

### Features

- **Multiple Environment Types**: 
  - Energy masks (static terrain with energy sources)
  - Sine wave patterns (periodic energy distribution)
  - Moving Perlin noise (dynamic, morphing terrain)

- **Interactive Controls**: 
  - Toggle rendering modes (topology vs energy visualization)
  - Switch environment types at runtime
  - Control energy harvesting
  - Reload simulations

- **Training Mode**: 
  - Evolve CNN populations using genetic algorithms
  - Multiprocessing evaluation for parallel fitness computation
  - Real-time graphing of evolution progress
  - Save/load trained models

- **Performance Optimizations**:
  - GPU-accelerated computation
  - Efficient memory management
  - Configurable rendering FPS

## Usage

### Running the Simulation

```bash
python main.py --load
```

This starts the interactive OpenGL simulation with default settings.

### Training CNNs

```bash
python main.py --train
```

This runs the genetic algorithm to evolve CNN populations. Training progress is displayed with matplotlib graphs.

### Loading Trained Models

```bash
python main.py --load
```

Loads the most recently trained model for use in simulation.

### Combining Options

```bash
python main.py --train --load
```

Starts training but initializes the population from the previously saved model.

## Configuration

All simulation parameters are configured in `config.py`. Key settings include:

- World size and organism count
- Environment type and noise parameters
- Energy harvesting, decay, and sharing rates
- Reproduction and death thresholds
- CNN training parameters (population size, mutation rates, epochs)
- Rendering and performance settings

For a complete list of all configuration options and their defaults, run:

```bash
python main.py --help
```

## Project Structure

```
OrganismEvolution/ 
├── main.py        # Main entry point with CLI
├── config.py      # Configuration parameters
├── gpu_handler.py # GPU device management
├── Grapher.py     # Evolution progress visualization
├── input_handler.py # Keyboard input handling
├── logger.py      # Performance logging
└── data/          # Saved CNN models
```

## Requirements

- Python 3.7+
- PyTorch (with MPS/CUDA support recommended)
- NumPy
- OpenGL (PyOpenGL, PyOpenGL-accelerate)
- GLUT
- matplotlib (for training graphs)
- scipy
- noise (for perlin noise generation)

## Notes

- The simulation runs at maximum speed; rendering FPS is controlled separately
- GPU acceleration significantly improves performance
- Trained models are saved automatically during evolution
- The simulation uses circular boundary conditions (wrapping)

For detailed information about all options, parameters, and controls, please run:

```bash
python main.py --help
```
